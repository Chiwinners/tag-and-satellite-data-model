{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e074b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Origen:  C:\\Users\\Crist\\Desktop\\NASA\\tag-and-satellite-data-model\\downloads\\sst\\sample\n",
      "üß∫ Parquet: C:\\Users\\Crist\\Desktop\\NASA\\tag-and-satellite-data-model\\transform\\sst\\sample (partitioned by year/month)\n",
      "üóÇÔ∏è  Archivos: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e3a210e7044caeb7cbc013c8db2688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando:   0%|          | 0/12 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Parquet listo en: C:\\Users\\Crist\\Desktop\\NASA\\tag-and-satellite-data-model\\transform\\sst\\sample\n",
      "üìà Filas exportadas: 6,972,000\n"
     ]
    }
   ],
   "source": [
    "# ASTER SKT GeoTIFF (.tif) -> lat, lon, timestamp, sst\n",
    "# Escritura incremental a Parquet particionado (year/month)\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# =========================\n",
    "# Localizaci√≥n carpetas\n",
    "# =========================\n",
    "def find_sst_sample_dir(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for parent in [start, *start.parents]:\n",
    "        cand = parent / \"downloads\" / \"sst\" / \"sample\"\n",
    "        if cand.is_dir():\n",
    "            return cand\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ 'downloads/sst/sample' desde {start}\")\n",
    "\n",
    "SAMPLE_DIR = find_sst_sample_dir()\n",
    "REPO_ROOT  = SAMPLE_DIR.parents[2]  # .../downloads/sst/sample -> subir 3 niveles\n",
    "OUT_PARQ   = (REPO_ROOT / \"transform\" / \"sst\" / \"sample\")\n",
    "OUT_PARQ.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Origen:  {SAMPLE_DIR}\")\n",
    "print(f\"üß∫ Parquet: {OUT_PARQ} (partitioned by year/month)\")\n",
    "\n",
    "# =========================\n",
    "# Configuraci√≥n\n",
    "# =========================\n",
    "# Submuestreo y l√≠mites (para memoria/volumen)\n",
    "FRACTION = 1.0            # 0<frac<=1 (ej. 0.2 para 20%)\n",
    "RANDOM_SEED = 42\n",
    "MAX_POINTS_PER_FILE = None  # p.ej. 2_000_000 para cap por archivo\n",
    "CHUNK_ROWS = 2_000_000      # escritura por bloques si excede\n",
    "\n",
    "# Unidades/escala de SST (no asumimos nada por defecto)\n",
    "SST_UNITS_MODE = \"raw\"      # \"raw\" | \"kelvin_from_tags\" | \"celsius_from_tags\"\n",
    "# Si el GeoTIFF trae tags 'scale_factor'/'add_offset', se usar√°n en *_from_tags\n",
    "\n",
    "# Mascara QA opcional (si existen *_QA_DataPlane*.tif); por defecto no se aplica\n",
    "USE_QA_MASK = False\n",
    "QA_GOOD_VALUE = 1           # si usas m√°scara binaria simple, 1 = bueno (ajusta si fuese distinto)\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# =========================\n",
    "# Dependencias\n",
    "# =========================\n",
    "if importlib.util.find_spec(\"rasterio\") is None:\n",
    "    raise RuntimeError(\"Instala rasterio:  python -m pip install rasterio\")\n",
    "if importlib.util.find_spec(\"pyproj\") is None:\n",
    "    raise RuntimeError(\"Instala pyproj:    python -m pip install pyproj\")\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from pyproj import Transformer\n",
    "\n",
    "# =========================\n",
    "# Utilidades\n",
    "# =========================\n",
    "def parse_ts_from_name(name: str):\n",
    "    \"\"\"\n",
    "    Extrae 'YYYYMMDDhhmmss' del nombre de archivo (p.ej. ..._20250702031314_SKT.tif).\n",
    "    Devuelve pandas.Timestamp(tz=UTC) o None.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"_(\\d{14})(?:_|\\.|$)\", name)\n",
    "    if not m:\n",
    "        return None\n",
    "    s = m.group(1)\n",
    "    return pd.Timestamp(f\"{s[:4]}-{s[4:6]}-{s[6:8]} {s[8:10]}:{s[10:12]}:{s[12:]}\", tz=\"UTC\")\n",
    "\n",
    "def sst_from_array(arr: np.ndarray, tags: dict, mode: str):\n",
    "    \"\"\"\n",
    "    Convierte DN a SST seg√∫n 'mode'. Por defecto 'raw' (sin cambios).\n",
    "    Si mode termina en '_from_tags', usa scale_factor/add_offset si est√°n presentes.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr, dtype=\"float32\")\n",
    "    if mode == \"raw\":\n",
    "        return arr\n",
    "\n",
    "    # Lee posibles tags de escala/desplazamiento (si existen)\n",
    "    sf = None; off = None\n",
    "    for k in (\"scale_factor\", \"SCALE\", \"Scale\", \"ScaleFactor\"):\n",
    "        if k in tags:\n",
    "            try: sf = float(tags[k]); break\n",
    "            except: pass\n",
    "    for k in (\"add_offset\", \"OFFSET\", \"Offset\"):\n",
    "        if k in tags:\n",
    "            try: off = float(tags[k]); break\n",
    "            except: pass\n",
    "    if sf is None:  sf = 1.0\n",
    "    if off is None: off = 0.0\n",
    "\n",
    "    kelvin = arr * sf + off\n",
    "    if mode == \"kelvin_from_tags\":\n",
    "        return kelvin\n",
    "    if mode == \"celsius_from_tags\":\n",
    "        return kelvin - 273.15\n",
    "    return arr  # fallback\n",
    "\n",
    "def qa_mask_for(path: Path):\n",
    "    \"\"\"\n",
    "    Busca un QA tif hermano ( *_QA_DataPlane*.tif ).\n",
    "    Devuelve (mask_bool | None).\n",
    "    \"\"\"\n",
    "    stem = path.name.replace(\"_SKT.tif\", \"\")\n",
    "    candidates = list(path.parent.glob(stem + \"_QA_DataPlane*.tif\"))\n",
    "    if not candidates:\n",
    "        return None\n",
    "    # Tomamos el primero\n",
    "    qa_path = candidates[0]\n",
    "    with rasterio.open(qa_path) as qsrc:\n",
    "        q = qsrc.read(1)  # asumimos misma georeferencia/tama√±o\n",
    "    # Heur√≠stica simple: m√°scara binaria (ajusta seg√∫n documentes los flags)\n",
    "    mask = (q == QA_GOOD_VALUE)\n",
    "    return mask\n",
    "\n",
    "def write_parquet_block(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "    df[\"year\"] = df[\"ts\"].dt.year.astype(\"int16\")\n",
    "    df[\"month\"] = df[\"ts\"].dt.month.astype(\"int8\")\n",
    "    table = pa.Table.from_pandas(df[[\"lat\",\"lon\",\"timestamp\",\"sst\",\"year\",\"month\"]], preserve_index=False)\n",
    "    pq.write_to_dataset(table,\n",
    "                        root_path=OUT_PARQ,\n",
    "                        partition_cols=[\"year\",\"month\"],\n",
    "                        compression=\"snappy\")\n",
    "\n",
    "# =========================\n",
    "# Proceso\n",
    "# =========================\n",
    "tifs = sorted(SAMPLE_DIR.glob(\"*_SKT.tif\"))\n",
    "assert tifs, f\"No hay *_SKT.tif en {SAMPLE_DIR}\"\n",
    "\n",
    "skipped = []\n",
    "total_rows = 0\n",
    "\n",
    "print(f\"üóÇÔ∏è  Archivos: {len(tifs)}\")\n",
    "for tif in tqdm(tifs, desc=\"Procesando\", unit=\"file\"):\n",
    "    try:\n",
    "        ts = parse_ts_from_name(tif.name)\n",
    "        if ts is None:\n",
    "            skipped.append((tif.name, \"sin timestamp en nombre\"))\n",
    "            continue\n",
    "\n",
    "        with rasterio.open(tif) as src:\n",
    "            # Datos\n",
    "            arr = src.read(1, masked=False)  # uint16 t√≠pico\n",
    "            tags = src.tags(1)  # tags de la banda para scale/offset si existen\n",
    "\n",
    "            # QA (opcional)\n",
    "            if USE_QA_MASK:\n",
    "                m = qa_mask_for(tif)\n",
    "                if m is not None and m.shape == arr.shape:\n",
    "                    arr = np.where(m, arr, np.nan)\n",
    "\n",
    "            # Construye malla de coordenadas en el CRS del raster\n",
    "            h, w = src.height, src.width\n",
    "            T: Affine = src.transform\n",
    "            # col, row centrados en p√≠xel\n",
    "            cols = (np.arange(w, dtype=\"float32\") + 0.5)[None, :]\n",
    "            rows = (np.arange(h, dtype=\"float32\") + 0.5)[:, None]\n",
    "            # x = a*col + b*row + c ; y = d*col + e*row + f\n",
    "            x = T.a * cols + T.b * rows + T.c\n",
    "            y = T.d * cols + T.e * rows + T.f\n",
    "\n",
    "            # Reproyecci√≥n a lon/lat (EPSG:4326)\n",
    "            transformer = Transformer.from_crs(src.crs, \"EPSG:4326\", always_xy=True)\n",
    "            lon, lat = transformer.transform(x, y)\n",
    "\n",
    "            # Convierte SST seg√∫n modo\n",
    "            sst = sst_from_array(arr, tags, SST_UNITS_MODE)\n",
    "\n",
    "            # Aplanar y filtrar finitos\n",
    "            lat_f = lat.ravel().astype(\"float32\")\n",
    "            lon_f = lon.ravel().astype(\"float32\")\n",
    "            sst_f = sst.ravel().astype(\"float32\")\n",
    "\n",
    "            finite = np.isfinite(lat_f) & np.isfinite(lon_f) & np.isfinite(sst_f)\n",
    "            if not finite.any():\n",
    "                skipped.append((tif.name, \"sin valores finitos tras m√°scara/escala\"))\n",
    "                continue\n",
    "\n",
    "            lat_f, lon_f, sst_f = lat_f[finite], lon_f[finite], sst_f[finite]\n",
    "\n",
    "            # Submuestreo y caps\n",
    "            n = lat_f.size\n",
    "            if FRACTION < 1.0:\n",
    "                k = max(1, int(np.ceil(n * FRACTION)))\n",
    "                idx = rng.choice(n, size=k, replace=False)\n",
    "                lat_f, lon_f, sst_f = lat_f[idx], lon_f[idx], sst_f[idx]\n",
    "                n = k\n",
    "            if (MAX_POINTS_PER_FILE is not None) and (n > MAX_POINTS_PER_FILE):\n",
    "                idx = rng.choice(n, size=MAX_POINTS_PER_FILE, replace=False)\n",
    "                lat_f, lon_f, sst_f = lat_f[idx], lon_f[idx], sst_f[idx]\n",
    "                n = MAX_POINTS_PER_FILE\n",
    "\n",
    "            # Escritura por bloques si es enorme\n",
    "            if (CHUNK_ROWS is not None) and (n > CHUNK_ROWS):\n",
    "                for i0 in range(0, n, CHUNK_ROWS):\n",
    "                    i1 = min(i0 + CHUNK_ROWS, n)\n",
    "                    df = pd.DataFrame({\n",
    "                        \"lat\": lat_f[i0:i1],\n",
    "                        \"lon\": lon_f[i0:i1],\n",
    "                        \"timestamp\": ts,\n",
    "                        \"sst\": sst_f[i0:i1],\n",
    "                    })\n",
    "                    write_parquet_block(df)\n",
    "                    total_rows += (i1 - i0)\n",
    "            else:\n",
    "                df = pd.DataFrame({\n",
    "                    \"lat\": lat_f,\n",
    "                    \"lon\": lon_f,\n",
    "                    \"timestamp\": ts,\n",
    "                    \"sst\": sst_f,\n",
    "                })\n",
    "                write_parquet_block(df)\n",
    "                total_rows += n\n",
    "\n",
    "    except Exception as e:\n",
    "        skipped.append((tif.name, f\"fall√≥ apertura/proceso: {e!s}\"))\n",
    "\n",
    "print(f\"\\n‚úÖ Parquet listo en: {OUT_PARQ}\")\n",
    "print(f\"üìà Filas exportadas: {total_rows:,}\")\n",
    "\n",
    "if skipped:\n",
    "    print(\"\\n‚ö†Ô∏è Skipped:\")\n",
    "    for name, reason in skipped:\n",
    "        print(f\"  - {name}: {reason}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
